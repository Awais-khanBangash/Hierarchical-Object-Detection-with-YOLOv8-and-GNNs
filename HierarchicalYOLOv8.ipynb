{
 "cells": [
  {
   "cell_type": "code",
   "id": "acbd7069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T19:18:14.230308Z",
     "start_time": "2025-07-31T19:18:13.992896Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.nn.modules import Conv, C2f, SPPF, Detect\n",
    "import networkx as nx\n",
    "from nltk.corpus import wordnet as wn\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class HierarchicalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_dir, ann_file, hierarchy_file, img_size=640):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_size = img_size\n",
    "        with open(hierarchy_file) as f:\n",
    "            self.hierarchy = json.load(f)\n",
    "        with open(ann_file) as f:\n",
    "            self.annotations = json.load(f)\n",
    "        \n",
    "        # Create class mappings\n",
    "        self.class_to_idx = {}\n",
    "        self.idx_to_class = {}\n",
    "        idx = 0\n",
    "        queue = [(\"root\", self.hierarchy)]\n",
    "        while queue:\n",
    "            path, node = queue.pop(0)\n",
    "            for cls, children in node.items():\n",
    "                full_path = f\"{path}/{cls}\" if path != \"root\" else cls\n",
    "                self.class_to_idx[full_path] = idx\n",
    "                self.idx_to_class[idx] = full_path\n",
    "                idx += 1\n",
    "                if children:\n",
    "                    queue.append((full_path, children))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        ann = self.annotations[idx]\n",
    "        img_path = os.path.join(self.img_dir, ann[\"image_file\"])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Resize image and adjust boxes\n",
    "        orig_w, orig_h = img.size\n",
    "        img = img.resize((self.img_size, self.img_size))\n",
    "        scale_x = self.img_size / orig_w\n",
    "        scale_y = self.img_size / orig_h\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for obj in ann[\"objects\"]:\n",
    "            # Find hierarchical path for this object\n",
    "            cls_path = self.find_class_path(obj[\"class_name\"])\n",
    "            if cls_path is None:\n",
    "                continue\n",
    "                \n",
    "            # Scale bounding boxes\n",
    "            box = obj[\"bbox\"]\n",
    "            box[0] *= scale_x  # xmin\n",
    "            box[1] *= scale_y  # ymin\n",
    "            box[2] *= scale_x  # xmax\n",
    "            box[3] *= scale_y  # ymax\n",
    "            boxes.append(box)\n",
    "            labels.append(self.class_to_idx[cls_path])\n",
    "        \n",
    "        img_tensor = torch.tensor(np.array(img), dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "        return {\n",
    "            \"image\": img_tensor,\n",
    "            \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.long),\n",
    "            \"original_size\": torch.tensor([orig_h, orig_w])\n",
    "        }\n",
    "    \n",
    "    def find_class_path(self, class_name):\n",
    "        queue = [(\"root\", self.hierarchy)]\n",
    "        while queue:\n",
    "            path, node = queue.pop(0)\n",
    "            for cls, children in node.items():\n",
    "                if cls.lower() == class_name.lower():\n",
    "                    return f\"{path}/{cls}\" if path != \"root\" else cls\n",
    "                if children:\n",
    "                    queue.append((f\"{path}/{cls}\" if path != \"root\" else cls, children))\n",
    "        return None\n",
    "\n",
    "class HierarchyGNN(nn.Module):\n",
    "    def __init__(self, num_classes, input_dim=256, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.gat1 = GATConv(input_dim, hidden_dim, heads=3)\n",
    "        self.gat2 = GATConv(hidden_dim*3, hidden_dim)\n",
    "        self.class_embed = nn.Embedding(num_classes, hidden_dim)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.class_embed(x)\n",
    "        x = F.relu(self.gat1(x, edge_index))\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class HierarchicalYOLOv8(nn.Module):\n",
    "    def __init__(self, num_classes, hierarchy):\n",
    "        super().__init__()\n",
    "        # Load pretrained YOLOv8\n",
    "        self.yolo = YOLO(\"yolov8n.yaml\").model\n",
    "        self.yolo.to(device)\n",
    "        \n",
    "        # Freeze backbone layers\n",
    "        for param in self.yolo.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # GNN for hierarchy\n",
    "        self.gnn = HierarchyGNN(num_classes).to(device)\n",
    "        \n",
    "        # Build hierarchy graph\n",
    "        self.graph = self.build_hierarchy_graph(hierarchy)\n",
    "        self.edge_index = self.graph.edge_index.to(device)\n",
    "        \n",
    "        # Modified detection head\n",
    "        self.detect = HierarchicalDetect(num_classes).to(device)\n",
    "    \n",
    "    def build_hierarchy_graph(self, hierarchy):\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        def add_nodes(parent, children):\n",
    "            for child, subchildren in children.items():\n",
    "                G.add_edge(parent, child)\n",
    "                if subchildren:\n",
    "                    add_nodes(child, subchildren)\n",
    "        \n",
    "        add_nodes(\"root\", hierarchy)\n",
    "        return from_networkx(G)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # YOLOv8 backbone\n",
    "        x = self.yolo(x)\n",
    "        \n",
    "        # GNN processing\n",
    "        node_features = torch.arange(len(self.graph.x)).to(device)\n",
    "        gnn_out = self.gnn(node_features, self.edge_index)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([x, gnn_out.unsqueeze(0).repeat(x.size(0), 1, 1)], dim=1)\n",
    "        \n",
    "        # Detection\n",
    "        return self.detect(combined)\n",
    "\n",
    "class HierarchicalDetect(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv = nn.Conv2d(256, num_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "def train(model, dataloader, epochs=50, lr=0.001):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "#  usage\n",
    "if __name__ == \"__main__\":\n",
    "    #  hierarchy\n",
    "    hierarchy = {\n",
    "        \"Animal\": {\n",
    "            \"Mammal\": {\n",
    "                \"Dog\": {\"Labrador\": {}, \"Poodle\": {}},\n",
    "                \"Cat\": {\"Persian\": {}, \"Siamese\": {}}\n",
    "            },\n",
    "            \"Bird\": {\"Eagle\": {}, \"Sparrow\": {}}\n",
    "        },\n",
    "        \"Vehicle\": {\n",
    "            \"Car\": {\"Sedan\": {}, \"SUV\": {}},\n",
    "            \"Truck\": {\"Pickup\": {}, \"Semi\": {}}\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = HierarchicalDataset(\n",
    "        img_dir=\"data/images\",\n",
    "        ann_file=\"data/annotations.json\",\n",
    "        hierarchy_file=\"data/hierarchy.json\"\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = HierarchicalYOLOv8(len(dataset.class_to_idx), hierarchy).to(device)\n",
    "    \n",
    "    # Train\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "    train(model, dataloader)\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), \"hierarchical_yolov8.pth\")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnn\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtorch\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mnn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfunctional\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mF\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'torch'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c6f3dcd7e1c38ee8"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
